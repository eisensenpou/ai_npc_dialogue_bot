{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "MODEL_NAME = \"facebook/blenderbot-400M-distill\"  # you can change this if you want. I preferred this model because it is lightweighted.\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlenderbotForConditionalGeneration(\n",
       "  (model): BlenderbotModel(\n",
       "    (shared): BlenderbotScaledWordEmbedding(8008, 1280, padding_idx=0)\n",
       "    (encoder): BlenderbotEncoder(\n",
       "      (embed_tokens): BlenderbotScaledWordEmbedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x BlenderbotEncoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BlenderbotDecoder(\n",
       "      (embed_tokens): BlenderbotScaledWordEmbedding(8008, 1280, padding_idx=0)\n",
       "      (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BlenderbotDecoderLayer(\n",
       "          (self_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BlenderbotAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1280, out_features=8008, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure model runs on GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Though this doesn't work as intended you can still use a this or improve it if you want your npc to remember chat history.\\\n",
    "# Load chat history if available\n",
    "#CHAT_HISTORY_FILE = \"chat_history.json\"\n",
    "\n",
    "#try:\n",
    "#    with open(CHAT_HISTORY_FILE, \"r\") as f:\n",
    "#        chat_history = json.load(f)\n",
    "#except FileNotFoundError:\n",
    "#    chat_history = []\n",
    "\n",
    "# Function to save the chat history\n",
    "#def save_chat_history():\n",
    "#    with open(CHAT_HISTORY_FILE, \"w\") as f:\n",
    "#        json.dump(chat_history, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a class to assign attributes and personal traits to npcs, you can adjust this class for your npcs since I added too many unnecessary attributes\n",
    "class Personality:\n",
    "    def __init__(self, name, age, skin_color, hair_type, hair_color, likes, dislikes,\n",
    "                 jobs=None, hobbies=None, relationship_status=None, education_level=None,\n",
    "                 favorite_color=None, location=None, motivation=None, personality_type=None,\n",
    "                 family_background=None, friends=None, favorite_food=None, health_status=None,\n",
    "                 political_views=None, social_media_presence=None, emotional_intelligence=None,\n",
    "                 sense_of_humor=None):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.skin_color = skin_color\n",
    "        self.hair_type = hair_type\n",
    "        self.hair_color = hair_color\n",
    "        self.likes = likes\n",
    "        self.dislikes = dislikes\n",
    "        self.jobs = jobs or []\n",
    "        self.hobbies = hobbies or []\n",
    "        self.relationship_status = relationship_status\n",
    "        self.education_level = education_level\n",
    "        self.favorite_color = favorite_color\n",
    "        self.location = location\n",
    "        self.motivation = motivation\n",
    "        self.personality_type = personality_type\n",
    "        self.family_background = family_background\n",
    "        self.friends = friends or []\n",
    "        self.favorite_food = favorite_food\n",
    "        self.health_status = health_status\n",
    "        self.political_views = political_views\n",
    "        self.social_media_presence = social_media_presence\n",
    "        self.emotional_intelligence = emotional_intelligence\n",
    "        self.sense_of_humor = sense_of_humor\n",
    "\n",
    "    # A method to describe our NPC object\n",
    "    def describe(self):\n",
    "        description = f\"Name: {self.name}\\nAge: {self.age}\\nSkin Color: {self.skin_color}\\n\"\n",
    "        description += f\"Hair Type: {self.hair_type}\\nHair Color: {self.hair_color}\\n\"\n",
    "        description += \"Likes: \" + \", \".join(self.likes) + \"\\n\"\n",
    "        description += \"Dislikes: \" + \", \".join(self.dislikes) + \"\\n\"\n",
    "\n",
    "        if self.jobs:\n",
    "            description += \"Jobs: \" + \", \".join(self.jobs) + \"\\n\"\n",
    "        if self.hobbies:\n",
    "            description += \"Hobbies: \" + \", \".join(self.hobbies) + \"\\n\"\n",
    "        if self.relationship_status:\n",
    "            description += f\"Relationship Status: {self.relationship_status}\\n\"\n",
    "        if self.education_level:\n",
    "            description += f\"Education Level: {self.education_level}\\n\"\n",
    "        if self.favorite_color:\n",
    "            description += f\"Favorite Color: {self.favorite_color}\\n\"\n",
    "        if self.location:\n",
    "            description += f\"Location: {self.location}\\n\"\n",
    "        if self.motivation:\n",
    "            description += f\"Motivation: {self.motivation}\\n\"\n",
    "        if self.personality_type:\n",
    "            description += f\"Personality Type: {self.personality_type}\\n\"\n",
    "        if self.family_background:\n",
    "            description += f\"Family Background: {self.family_background}\\n\"\n",
    "        if self.friends:\n",
    "            description += \"Friends: \" + \", \".join(self.friends) + \"\\n\"\n",
    "        if self.favorite_food:\n",
    "            description += f\"Favorite Food: {self.favorite_food}\\n\"\n",
    "        if self.health_status:\n",
    "            description += f\"Health Status: {self.health_status}\\n\"\n",
    "        if self.political_views:\n",
    "            description += f\"Political Views: {self.political_views}\\n\"\n",
    "        if self.social_media_presence:\n",
    "            description += f\"Social Media: {self.social_media_presence}\\n\"\n",
    "        if self.emotional_intelligence:\n",
    "            description += f\"Emotional Intelligence: {self.emotional_intelligence}\\n\"\n",
    "        if self.sense_of_humor:\n",
    "            description += f\"Senses of Humor: {self.sense_of_humor}\\n\"\n",
    "\n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alice's personality for test purposes\n",
    "alice = Personality(\n",
    "    name=\"Alice\",\n",
    "    age=25,\n",
    "    skin_color=\"light\",\n",
    "    hair_type=\"straight\",\n",
    "    hair_color=\"brown\",\n",
    "    likes=[\"reading\", \"playing video games\", \"hiking\", \"gym\", \"working\"],\n",
    "    dislikes=[\"loud noises\", \"early mornings\", \"alcohol\", \"cigars\"],\n",
    "    jobs=[\"Software Engineer\"],\n",
    "    hobbies=[\"painting\", \"traveling\"],\n",
    "    relationship_status=\"Single\",\n",
    "    education_level=\"Bachelor's degree in Computer Science\",\n",
    "    favorite_color=\"Blue\",\n",
    "    location=\"New York\",\n",
    "    motivation=\"To become a great software developer and explore the world.\",\n",
    "    personality_type=\"Ambivert\",\n",
    "    family_background=\"Raised in a close-knit family with two siblings.\",\n",
    "    friends=[\"John\", \"Sophia\", \"Mark\"],\n",
    "    favorite_food=\"Pizza\",\n",
    "    health_status=\"Health-conscious, enjoys yoga and hiking\",\n",
    "    political_views=\"Moderate, focused on social equality\",\n",
    "    social_media_presence=\"Active on Instagram and Twitter, but private\",\n",
    "    emotional_intelligence=\"High, very empathetic\",\n",
    "    sense_of_humor=\"Dry and sarcastic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alice\n",
      "Age: 25\n",
      "Skin Color: light\n",
      "Hair Type: straight\n",
      "Hair Color: brown\n",
      "Likes: reading, playing video games, hiking, gym, working\n",
      "Dislikes: loud noises, early mornings, alcohol, cigars\n",
      "Jobs: Software Engineer\n",
      "Hobbies: painting, traveling\n",
      "Relationship Status: Single\n",
      "Education Level: Bachelor's degree in Computer Science\n",
      "Favorite Color: Blue\n",
      "Location: New York\n",
      "Motivation: To become a great software developer and explore the world.\n",
      "Personality Type: Ambivert\n",
      "Family Background: Raised in a close-knit family with two siblings.\n",
      "Friends: John, Sophia, Mark\n",
      "Favorite Food: Pizza\n",
      "Health Status: Health-conscious, enjoys yoga and hiking\n",
      "Political Views: Moderate, focused on social equality\n",
      "Social Media: Active on Instagram and Twitter, but private\n",
      "Emotional Intelligence: High, very empathetic\n",
      "Senses of Humor: Dry and sarcastic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Alice's description\n",
    "alice_description = alice.describe()\n",
    "print(alice_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot response function\n",
    "def chatbot_response(user_input):\n",
    "    if \"tell me about yourself\" in user_input.lower():\n",
    "        return alice_description\n",
    "    else:\n",
    "        return \"I'm Alice. How can I assist you today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Append user input to chat history\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#chat_history.append({\"role\": \"user\", \"message\": user_input})\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Tokenize input\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#inputs = tokenizer(conversation, return_tensors=\"pt\").to(device)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[0;32m     20\u001b[0m reply_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gerha\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2871\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2869\u001b[0m all_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   2870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2871\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either `text` or `text_target`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2873\u001b[0m     \u001b[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001b[39;00m\n\u001b[0;32m   2874\u001b[0m     \u001b[38;5;66;03m# input mode in this case.\u001b[39;00m\n\u001b[0;32m   2875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n",
      "\u001b[1;31mValueError\u001b[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "source": [
    "# Main conversation loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    if user_input.lower() == \"quit\":\n",
    "        #save_chat_history()\n",
    "        break\n",
    "\n",
    "    # Append user input to chat history\n",
    "    #chat_history.append({\"role\": \"user\", \"message\": user_input})\n",
    "\n",
    "    # Combine history into a single conversation string (keep the last 5 exchanges)\n",
    "    #conversation = \" \".join([msg[\"message\"] for msg in chat_history[-5:]])\n",
    "\n",
    "    # Tokenize input\n",
    "    #inputs = tokenizer(conversation, return_tensors=\"pt\").to(device)\n",
    "    inputs = tokenizer(return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate response\n",
    "    reply_ids = model.generate(inputs[\"input_ids\"], max_length=50)\n",
    "    response = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Append AI response to chat history\n",
    "    #chat_history.append({\"role\": \"ai\", \"message\": response})\n",
    "\n",
    "    # Output response\n",
    "    print(\"AI:\", response)\n",
    "\n",
    "    # Save the updated chat history after each conversation\n",
    "    #save_chat_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always improve your chat responses by defining a more detailed functions to control the bot's answers.\n",
    "This is pretty much it.\n",
    "Let me know if you have any suggestions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
